{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3 Pattern Mining and Recommender Systems: Individual Code\n",
    "\n",
    "### Task 2: Collaborative Filtering\n",
    "\n",
    "### Ky Cuong Pham, 1906313, Version 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Date</th>\n",
       "      <th>itemDescription</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2351</td>\n",
       "      <td>1/01/2014</td>\n",
       "      <td>cleaner</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2226</td>\n",
       "      <td>1/01/2014</td>\n",
       "      <td>sausage</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1922</td>\n",
       "      <td>1/01/2014</td>\n",
       "      <td>tropical fruit</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2943</td>\n",
       "      <td>1/01/2014</td>\n",
       "      <td>whole milk</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1249</td>\n",
       "      <td>1/01/2014</td>\n",
       "      <td>citrus fruit</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_id       Date itemDescription  year  month  day  day_of_week\n",
       "0     2351  1/01/2014         cleaner  2014      1    1            2\n",
       "1     2226  1/01/2014         sausage  2014      1    1            2\n",
       "2     1922  1/01/2014  tropical fruit  2014      1    1            2\n",
       "3     2943  1/01/2014      whole milk  2014      1    1            2\n",
       "4     1249  1/01/2014    citrus fruit  2014      1    1            2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv(\"data/Groceries data train.csv\")\n",
    "data = data.dropna()\n",
    "\n",
    "# Convert columns to appropriate types\n",
    "data['User_id'] = data['User_id'].astype('int')\n",
    "data['year'] = data['year'].astype('int')\n",
    "data['month'] = data['month'].astype('int')\n",
    "data['day'] = data['day'].astype('int')\n",
    "data['day_of_week'] = data['day_of_week'].astype('int')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-model-based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3493, 167)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>itemDescription</th>\n",
       "      <th>Instant food products</th>\n",
       "      <th>UHT-milk</th>\n",
       "      <th>abrasive cleaner</th>\n",
       "      <th>artif. sweetener</th>\n",
       "      <th>baby cosmetics</th>\n",
       "      <th>bags</th>\n",
       "      <th>baking powder</th>\n",
       "      <th>bathroom cleaner</th>\n",
       "      <th>beef</th>\n",
       "      <th>berries</th>\n",
       "      <th>...</th>\n",
       "      <th>turkey</th>\n",
       "      <th>vinegar</th>\n",
       "      <th>waffles</th>\n",
       "      <th>whipped/sour cream</th>\n",
       "      <th>whisky</th>\n",
       "      <th>white bread</th>\n",
       "      <th>white wine</th>\n",
       "      <th>whole milk</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>zwieback</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 167 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "itemDescription  Instant food products  UHT-milk  abrasive cleaner  \\\n",
       "User_id                                                              \n",
       "1000                                 0         0                 0   \n",
       "1001                                 0         0                 0   \n",
       "1002                                 0         0                 0   \n",
       "1003                                 0         0                 0   \n",
       "1004                                 0         0                 0   \n",
       "\n",
       "itemDescription  artif. sweetener  baby cosmetics  bags  baking powder  \\\n",
       "User_id                                                                  \n",
       "1000                            0               0     0              0   \n",
       "1001                            0               0     0              0   \n",
       "1002                            0               0     0              0   \n",
       "1003                            0               0     0              0   \n",
       "1004                            0               0     0              0   \n",
       "\n",
       "itemDescription  bathroom cleaner  beef  berries  ...  turkey  vinegar  \\\n",
       "User_id                                           ...                    \n",
       "1000                            0     0        0  ...       0        0   \n",
       "1001                            0     0        0  ...       0        0   \n",
       "1002                            0     0        0  ...       0        0   \n",
       "1003                            0     0        0  ...       0        0   \n",
       "1004                            0     0        0  ...       0        0   \n",
       "\n",
       "itemDescription  waffles  whipped/sour cream  whisky  white bread  white wine  \\\n",
       "User_id                                                                         \n",
       "1000                   0                   0       0            0           0   \n",
       "1001                   0                   0       0            0           0   \n",
       "1002                   0                   0       0            0           0   \n",
       "1003                   0                   0       0            0           0   \n",
       "1004                   0                   0       0            0           0   \n",
       "\n",
       "itemDescription  whole milk  yogurt  zwieback  \n",
       "User_id                                        \n",
       "1000                      1       0         0  \n",
       "1001                      2       0         0  \n",
       "1002                      1       0         0  \n",
       "1003                      0       0         0  \n",
       "1004                      3       0         0  \n",
       "\n",
       "[5 rows x 167 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_matrix = data.groupby(['User_id', 'itemDescription']).size().unstack(fill_value=0)\n",
    "\n",
    "print(user_item_matrix.shape)\n",
    "user_item_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       "\twith 18288 stored elements and shape (3493, 167)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Convert to sparse matrix for efficiency\n",
    "matrix = csr_matrix(user_item_matrix.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>User_id</th>\n",
       "      <th>1000</th>\n",
       "      <th>1001</th>\n",
       "      <th>1002</th>\n",
       "      <th>1003</th>\n",
       "      <th>1004</th>\n",
       "      <th>1005</th>\n",
       "      <th>1006</th>\n",
       "      <th>1009</th>\n",
       "      <th>1010</th>\n",
       "      <th>1011</th>\n",
       "      <th>...</th>\n",
       "      <th>4988</th>\n",
       "      <th>4989</th>\n",
       "      <th>4990</th>\n",
       "      <th>4991</th>\n",
       "      <th>4992</th>\n",
       "      <th>4993</th>\n",
       "      <th>4995</th>\n",
       "      <th>4997</th>\n",
       "      <th>4999</th>\n",
       "      <th>5000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.348155</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.218218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>0.348155</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.301511</td>\n",
       "      <td>0.213201</td>\n",
       "      <td>0.447914</td>\n",
       "      <td>0.246183</td>\n",
       "      <td>0.341882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.123091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.213201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.161165</td>\n",
       "      <td>0.123091</td>\n",
       "      <td>0.123091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.426401</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.301511</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.371391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400892</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.213201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.328266</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.267261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176777</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>0.428845</td>\n",
       "      <td>0.447914</td>\n",
       "      <td>0.371391</td>\n",
       "      <td>0.328266</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.303239</td>\n",
       "      <td>0.421117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055989</td>\n",
       "      <td>0.227429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.262613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397033</td>\n",
       "      <td>0.075810</td>\n",
       "      <td>0.303239</td>\n",
       "      <td>0.092848</td>\n",
       "      <td>0.525226</td>\n",
       "      <td>0.092848</td>\n",
       "      <td>0.092848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3493 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "User_id      1000      1001      1002      1003      1004      1005      1006  \\\n",
       "User_id                                                                         \n",
       "1000     1.000000  0.348155  0.288675  0.000000  0.428845  0.000000  0.218218   \n",
       "1001     0.348155  1.000000  0.301511  0.213201  0.447914  0.246183  0.341882   \n",
       "1002     0.288675  0.301511  1.000000  0.000000  0.371391  0.000000  0.188982   \n",
       "1003     0.000000  0.213201  0.000000  1.000000  0.328266  0.577350  0.267261   \n",
       "1004     0.428845  0.447914  0.371391  0.328266  1.000000  0.303239  0.421117   \n",
       "\n",
       "User_id  1009      1010      1011  ...      4988      4989  4990      4991  \\\n",
       "User_id                            ...                                       \n",
       "1000      0.0  0.000000  0.235702  ...  0.000000  0.000000   0.0  0.154303   \n",
       "1001      0.0  0.090909  0.123091  ...  0.000000  0.213201   0.0  0.161165   \n",
       "1002      0.0  0.000000  0.000000  ...  0.447214  0.353553   0.0  0.400892   \n",
       "1003      0.0  0.000000  0.288675  ...  0.000000  0.500000   0.0  0.188982   \n",
       "1004      0.0  0.055989  0.227429  ...  0.000000  0.262613   0.0  0.397033   \n",
       "\n",
       "User_id      4992      4993      4995      4997      4999      5000  \n",
       "User_id                                                              \n",
       "1000     0.000000  0.000000  0.000000  0.408248  0.000000  0.000000  \n",
       "1001     0.123091  0.123091  0.000000  0.426401  0.000000  0.000000  \n",
       "1002     0.000000  0.000000  0.000000  0.353553  0.250000  0.250000  \n",
       "1003     0.000000  0.433013  0.000000  0.000000  0.176777  0.000000  \n",
       "1004     0.075810  0.303239  0.092848  0.525226  0.092848  0.092848  \n",
       "\n",
       "[5 rows x 3493 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    " # Calculate cosine similarity between users\n",
    "user_similarity = cosine_similarity(matrix) #user and user\n",
    "# Create user similarity DataFrame\n",
    "user_similarity_df = pd.DataFrame(\n",
    "    user_similarity,\n",
    "    index=user_item_matrix.index,\n",
    "    columns=user_item_matrix.index\n",
    ")\n",
    "\n",
    "user_similarity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 similar users to User 3247:\n",
      "User 4959: Similarity = 0.6629\n",
      "User 2658: Similarity = 0.6250\n",
      "User 2850: Similarity = 0.6250\n",
      "User 3725: Similarity = 0.6187\n",
      "User 3146: Similarity = 0.6187\n",
      "User 4723: Similarity = 0.6187\n",
      "User 3660: Similarity = 0.6124\n",
      "User 1040: Similarity = 0.5893\n",
      "User 4206: Similarity = 0.5784\n",
      "User 2617: Similarity = 0.5745\n"
     ]
    }
   ],
   "source": [
    "user_id = 3247\n",
    "n_neighbors = 10\n",
    "top_n = 10\n",
    "\n",
    "# Get similar users (excluding the target user)\n",
    "user_idx = user_item_matrix.index.get_loc(user_id)\n",
    "similar_users = user_similarity_df.iloc[user_idx].sort_values(ascending=False)[1:n_neighbors+1]\n",
    "\n",
    "print(f\"Top {n_neighbors} similar users to User {user_id}:\")\n",
    "for sim_user_id, similarity in similar_users.items():\n",
    "    print(f\"User {sim_user_id}: Similarity = {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Instant food products',\n",
       " 'abrasive cleaner',\n",
       " 'artif. sweetener',\n",
       " 'baby cosmetics',\n",
       " 'bags',\n",
       " 'baking powder',\n",
       " 'bathroom cleaner',\n",
       " 'beef',\n",
       " 'berries',\n",
       " 'beverages',\n",
       " 'bottled beer',\n",
       " 'bottled water',\n",
       " 'brandy',\n",
       " 'brown bread',\n",
       " 'butter',\n",
       " 'butter milk',\n",
       " 'cake bar',\n",
       " 'candles',\n",
       " 'canned fish',\n",
       " 'canned fruit',\n",
       " 'canned vegetables',\n",
       " 'cereals',\n",
       " 'chewing gum',\n",
       " 'chicken',\n",
       " 'chocolate',\n",
       " 'chocolate marshmallow',\n",
       " 'citrus fruit',\n",
       " 'cleaner',\n",
       " 'cling film/bags',\n",
       " 'cocoa drinks',\n",
       " 'condensed milk',\n",
       " 'cooking chocolate',\n",
       " 'cookware',\n",
       " 'cream',\n",
       " 'cream cheese ',\n",
       " 'curd',\n",
       " 'curd cheese',\n",
       " 'decalcifier',\n",
       " 'dental care',\n",
       " 'dessert',\n",
       " 'detergent',\n",
       " 'dish cleaner',\n",
       " 'dog food',\n",
       " 'domestic eggs',\n",
       " 'female sanitary products',\n",
       " 'finished products',\n",
       " 'fish',\n",
       " 'flour',\n",
       " 'flower (seeds)',\n",
       " 'flower soil/fertilizer',\n",
       " 'frankfurter',\n",
       " 'frozen chicken',\n",
       " 'frozen dessert',\n",
       " 'frozen fish',\n",
       " 'frozen fruits',\n",
       " 'frozen meals',\n",
       " 'frozen potato products',\n",
       " 'grapes',\n",
       " 'hair spray',\n",
       " 'ham',\n",
       " 'hamburger meat',\n",
       " 'hard cheese',\n",
       " 'herbs',\n",
       " 'honey',\n",
       " 'house keeping products',\n",
       " 'hygiene articles',\n",
       " 'ice cream',\n",
       " 'instant coffee',\n",
       " 'jam',\n",
       " 'ketchup',\n",
       " 'kitchen towels',\n",
       " 'kitchen utensil',\n",
       " 'light bulbs',\n",
       " 'liqueur',\n",
       " 'liquor',\n",
       " 'liquor (appetizer)',\n",
       " 'liver loaf',\n",
       " 'long life bakery product',\n",
       " 'make up remover',\n",
       " 'male cosmetics',\n",
       " 'margarine',\n",
       " 'mayonnaise',\n",
       " 'meat',\n",
       " 'meat spreads',\n",
       " 'mustard',\n",
       " 'napkins',\n",
       " 'newspapers',\n",
       " 'nut snack',\n",
       " 'nuts/prunes',\n",
       " 'oil',\n",
       " 'onions',\n",
       " 'organic products',\n",
       " 'organic sausage',\n",
       " 'packaged fruit/vegetables',\n",
       " 'pasta',\n",
       " 'pet care',\n",
       " 'photo/film',\n",
       " 'pickled vegetables',\n",
       " 'popcorn',\n",
       " 'pork',\n",
       " 'pot plants',\n",
       " 'potato products',\n",
       " 'preservation products',\n",
       " 'processed cheese',\n",
       " 'prosecco',\n",
       " 'pudding powder',\n",
       " 'ready soups',\n",
       " 'red/blush wine',\n",
       " 'roll products ',\n",
       " 'rubbing alcohol',\n",
       " 'rum',\n",
       " 'salad dressing',\n",
       " 'salt',\n",
       " 'salty snack',\n",
       " 'sauces',\n",
       " 'sausage',\n",
       " 'seasonal products',\n",
       " 'semi-finished bread',\n",
       " 'shopping bags',\n",
       " 'skin care',\n",
       " 'snack products',\n",
       " 'soap',\n",
       " 'soda',\n",
       " 'soft cheese',\n",
       " 'softener',\n",
       " 'soups',\n",
       " 'sparkling wine',\n",
       " 'specialty bar',\n",
       " 'specialty cheese',\n",
       " 'specialty chocolate',\n",
       " 'specialty fat',\n",
       " 'specialty vegetables',\n",
       " 'spices',\n",
       " 'sweet spreads',\n",
       " 'syrup',\n",
       " 'tea',\n",
       " 'tidbits',\n",
       " 'toilet cleaner',\n",
       " 'tropical fruit',\n",
       " 'turkey',\n",
       " 'vinegar',\n",
       " 'waffles',\n",
       " 'whipped/sour cream',\n",
       " 'whisky',\n",
       " 'white bread',\n",
       " 'white wine'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get items that the target user hasn't purchased\n",
    "user_items = set(user_item_matrix.columns[user_item_matrix.loc[user_id] > 0])\n",
    "items_to_recommend = set(user_item_matrix.columns) - user_items\n",
    "items_to_recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chewing gum', 1.0),\n",
       " ('bottled beer', 1.0),\n",
       " ('white bread', 1.0),\n",
       " ('pasta', 1.0),\n",
       " ('oil', 1.0),\n",
       " ('ham', 1.0),\n",
       " ('margarine', 1.0),\n",
       " ('frozen meals', 1.0),\n",
       " ('rubbing alcohol', 1.0),\n",
       " ('liquor', 1.0)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate recommendation scores\n",
    "recommendations = {}\n",
    "\n",
    "for item in items_to_recommend:\n",
    "    score = 0\n",
    "    total_similarity = 0\n",
    "    \n",
    "    for sim_user_id, similarity in similar_users.items():\n",
    "        # If similar user has purchased this item\n",
    "        if user_item_matrix.loc[sim_user_id, item] > 0:\n",
    "            score += similarity * user_item_matrix.loc[sim_user_id, item]\n",
    "            total_similarity += similarity\n",
    "    \n",
    "    # Normalize score by total similarity if possible\n",
    "    if total_similarity > 0:\n",
    "        recommendations[item] = score / total_similarity # sum(similarity * rating)/sum(similarity)\n",
    "\n",
    "# Sort recommendations by score\n",
    "sorted_recommendations = sorted(recommendations.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Return top N recommendations\n",
    "sorted_recommendations[:top_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0415\n",
      "RMSE of the SVD model: 0.041528792726574386\n",
      "Top 10 recommendations for User 3247:\n",
      "chewing gum: Predicted score = 1.0000\n",
      "bottled beer: Predicted score = 1.0000\n",
      "liqueur: Predicted score = 1.0000\n",
      "curd: Predicted score = 1.0000\n",
      "newspapers: Predicted score = 1.0000\n",
      "cocoa drinks: Predicted score = 1.0000\n",
      "dog food: Predicted score = 1.0000\n",
      "photo/film: Predicted score = 1.0000\n",
      "condensed milk: Predicted score = 1.0000\n",
      "tropical fruit: Predicted score = 1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import necessary libraries from Surprise\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(\"data/Groceries data train.csv\")\n",
    "data = data.dropna()\n",
    "\n",
    "# Convert the 'Date' column to datetime\n",
    "data['Date'] = pd.to_datetime(data['Date'], format='%d/%m/%Y')\n",
    "\n",
    "# Create a binary column for purchase (1 if the user bought the item, else 0)\n",
    "data['purchase'] = 1  # Assuming each row represents a purchase\n",
    "\n",
    "# Create the user-item interaction matrix\n",
    "user_item_matrix = data.groupby(['User_id', 'itemDescription'])['purchase'].max().unstack(fill_value=0)\n",
    "\n",
    "# Prepare the data for Surprise library\n",
    "reader = Reader(rating_scale=(0, 1))  # Binary ratings (0 or 1)\n",
    "data_surprise = Dataset.load_from_df(data[['User_id', 'itemDescription', 'purchase']], reader)\n",
    "\n",
    "# Split data into training and testing sets (80% training, 20% testing)\n",
    "trainset, testset = train_test_split(data_surprise, test_size=0.2)\n",
    "\n",
    "# Build and train the SVD model\n",
    "svd = SVD()\n",
    "svd.fit(trainset)\n",
    "\n",
    "# Make predictions on the testset\n",
    "predictions = svd.test(testset)\n",
    "\n",
    "# Evaluate the model performance using RMSE (Root Mean Squared Error)\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print(f\"RMSE of the SVD model: {rmse}\")\n",
    "\n",
    "# Get items that the target user hasn't purchased\n",
    "user_items = set(user_item_matrix.columns[user_item_matrix.loc[user_id] > 0])\n",
    "items_to_recommend = set(user_item_matrix.columns) - user_items\n",
    "\n",
    "# Calculate recommendation scores\n",
    "recommendations = {}\n",
    "for item in items_to_recommend:\n",
    "    # Predict if the user will buy the item\n",
    "    pred = svd.predict(user_id, item)\n",
    "    recommendations[item] = pred.est\n",
    "\n",
    "# Sort recommendations by the predicted score\n",
    "sorted_recommendations = sorted(recommendations.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Show the top N recommendations\n",
    "print(f\"Top {top_n} recommendations for User {user_id}:\")\n",
    "for item, score in sorted_recommendations[:top_n]:\n",
    "    print(f\"{item}: Predicted score = {score:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>itemDescription</th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2351.0</td>\n",
       "      <td>cleaner</td>\n",
       "      <td>1170</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2226.0</td>\n",
       "      <td>sausage</td>\n",
       "      <td>1062</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1922.0</td>\n",
       "      <td>tropical fruit</td>\n",
       "      <td>807</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2943.0</td>\n",
       "      <td>whole milk</td>\n",
       "      <td>1688</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1249.0</td>\n",
       "      <td>citrus fruit</td>\n",
       "      <td>215</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_id itemDescription  user  item\n",
       "0   2351.0         cleaner  1170    31\n",
       "1   2226.0         sausage  1062   130\n",
       "2   1922.0  tropical fruit   807   156\n",
       "3   2943.0      whole milk  1688   164\n",
       "4   1249.0    citrus fruit   215    30"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('data/Groceries data train.csv')  # or use pd.read_csv(io.StringIO(...)) if you're pasting it\n",
    "\n",
    "# Encode user_id and itemDescription\n",
    "user_encoder = LabelEncoder()\n",
    "item_encoder = LabelEncoder()\n",
    "\n",
    "df['user'] = user_encoder.fit_transform(df['User_id'])\n",
    "df['item'] = item_encoder.fit_transform(df['itemDescription'])\n",
    "\n",
    "# Preview\n",
    "df[['User_id', 'itemDescription', 'user', 'item']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample interactions: [(1170, 31), (1062, 130), (807, 156), (1688, 164), (215, 30)]\n",
      "Users: 3494 Items: 168\n"
     ]
    }
   ],
   "source": [
    "interactions = list(zip(df['user'], df['item']))\n",
    "num_users = df['user'].nunique()\n",
    "num_items = df['item'].nunique()\n",
    "\n",
    "# Show a few examples\n",
    "print(\"Sample interactions:\", interactions[:5])\n",
    "print(\"Users:\", num_users, \"Items:\", num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 23493, Test: 3492\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the interactions list into a training set and a test set, but in a user-aware way — meaning:\n",
    "\n",
    "# Each user gets their own data split\n",
    "\n",
    "# We ensure at least one test interaction per user (if possible)\n",
    "\n",
    "# This is important for recommender systems to fairly evaluate generalization per user\n",
    "\n",
    "\n",
    "\n",
    "# Convert to DataFrame for easier splitting\n",
    "interactions_df = pd.DataFrame(interactions, columns=['user', 'item'])\n",
    "\n",
    "# Group by user and split each user's items\n",
    "train_interactions = []\n",
    "test_interactions = []\n",
    "\n",
    "for user_id, user_data in interactions_df.groupby('user'):\n",
    "    items = user_data['item'].tolist()\n",
    "    if len(items) < 2: # If a user has less than 2 items, there's no point in splitting — we keep all their items in training\n",
    "        train_interactions.extend([(user_id, i) for i in items])\n",
    "        continue\n",
    "    train_items, test_items = train_test_split(items, test_size=1) # 1 item for testing\n",
    "    train_interactions.extend([(user_id, i) for i in train_items])\n",
    "    test_interactions.extend([(user_id, i) for i in test_items])\n",
    "\n",
    "print(f\"Train: {len(train_interactions)}, Test: {len(test_interactions)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "class MLPDataset(Dataset):\n",
    "    def __init__(self, interactions, num_users, num_items, num_negatives=4):\n",
    "        self.data = []\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.interactions = set(interactions)\n",
    "        for (u, i) in interactions:\n",
    "            self.data.append((u, i, 1))  # positive\n",
    "            for _ in range(num_negatives):\n",
    "                j = random.randint(0, num_items - 1)\n",
    "                while (u, j) in self.interactions:\n",
    "                    j = random.randint(0, num_items - 1)\n",
    "                self.data.append((u, j, 0))  # negative\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user, item, label = self.data[idx]\n",
    "        return torch.tensor(user), torch.tensor(item), torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "class MLPRec(nn.Module):\n",
    "    def __init__(self, num_users, num_items, layers=[64,32,16,8]):\n",
    "        super(MLPRec, self).__init__()\n",
    "        self.embedding_user = nn.Embedding(num_users, layers[0] // 2)\n",
    "        self.embedding_item = nn.Embedding(num_items, layers[0] // 2)\n",
    "        \n",
    "        mlp_layers = []\n",
    "        input_size = layers[0]\n",
    "        for layer_size in layers[1:]:\n",
    "            mlp_layers.append(nn.Linear(input_size, layer_size))\n",
    "            mlp_layers.append(nn.ReLU())\n",
    "            input_size = layer_size\n",
    "            \n",
    "        self.mlp = nn.Sequential(*mlp_layers)\n",
    "        self.output = nn.Linear(layers[-1], 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        user_emb = self.embedding_user(user)\n",
    "        item_emb = self.embedding_item(item)\n",
    "        x = torch.cat([user_emb, item_emb], dim=-1)\n",
    "        x = self.mlp(x)\n",
    "        x = self.output(x)\n",
    "        return self.sigmoid(x).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:44<00:00,  4.50s/it]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MLPDataset(train_interactions, num_users, num_items)\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "\n",
    "model = MLPRec(num_users, num_items)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "history = []\n",
    "\n",
    "epochs = 10\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for user, item, label in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(user, item)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    history.append(total_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.5108\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "true_labels = []\n",
    "pred_scores = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (u, i) in train_interactions:\n",
    "        user_tensor = torch.tensor([u])\n",
    "        item_tensor = torch.tensor([i])\n",
    "        pred = model(user_tensor, item_tensor).item()\n",
    "        pred_scores.append(pred)\n",
    "        true_labels.append(1.0)  # All test interactions are positive\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(true_labels, pred_scores))\n",
    "print(f\"Train RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.6664\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "true_labels = []\n",
    "pred_scores = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (u, i) in test_interactions:\n",
    "        user_tensor = torch.tensor([u])\n",
    "        item_tensor = torch.tensor([i])\n",
    "        pred = model(user_tensor, item_tensor).item()\n",
    "        pred_scores.append(pred)\n",
    "        true_labels.append(1.0)  # All test interactions are positive\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(true_labels, pred_scores))\n",
    "print(f\"Test RMSE: {rmse:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
